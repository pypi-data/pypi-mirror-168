{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link G-drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTooJbLTkDWl"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "4362PEEZfpQB",
    "outputId": "3225a4d8-7859-46d9-e634-2d86d52c23e0"
   },
   "outputs": [],
   "source": [
    "import sigma\n",
    "from sigma.utils import normalisation as norm \n",
    "from sigma.utils import visualisation as visual\n",
    "from sigma.utils.load import SEMDataset\n",
    "from sigma.src.utils import same_seeds\n",
    "from sigma.src.dim_reduction import Experiment\n",
    "from sigma.models.autoencoder import AutoEncoder\n",
    "from sigma.src.segmentation import PixelSegmenter\n",
    "from sigma.gui import gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olPzlO4gsAuG"
   },
   "source": [
    "# Load files\n",
    "\n",
    "Load the *.bcf* file and create an object of `SEMDataset` (which uses hyperspy as backend.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wd0omy47rJb"
   },
   "outputs": [],
   "source": [
    "!gdown --id '1woNRlyrBbUDIClYp_HNldzA2evdpArsi' -O 'test.bcf'\n",
    "\n",
    "file_path = 'test.bcf'\n",
    "sem = SEMDataset(file_path)\n",
    "sem.set_feature_list(['Al_Ka', 'C_Ka', 'Ca_Ka', 'Fe_Ka', 'K_Ka', 'O_Ka', 'Si_Ka', 'Ti_Ka', 'Zn_La'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the file with GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "file_path=list(uploaded.keys())[0]\n",
    "sem = SEMDataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpqYK5B6m-3k"
   },
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the dataset\n",
    "\n",
    "Use `gui.view_bcf_dataset(sem)` to check the BSE image, the sum spectrum, and the elemental maps. Here we can use the small widgets to search the energy peaks and determine the elements for further amalyses. \n",
    "\n",
    "After setting the `Feature list`, we obtain the elemental maps hyperspectral imaging dataset (HSI) with the dimension of 279 x 514 x 9 (for the test file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRccG0O2plY_",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gui.view_bcf_dataset(sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the GUI, we can view the dataset with the `sem` object:\n",
    "\n",
    "1. `sem.bse`: access the back-scattered electron (as a hyperspy format).\n",
    "\n",
    "2. `sem.edx`: access the edx dataset (as a hyperspy format).\n",
    "\n",
    "3. `visual.plot_sum_spectrum(sem.edx)`: view the sum spectrum (or use hyperspy built-in function `sem.edx.sum().plot(xray_lines=True)`).\n",
    "\n",
    "4. `sem.feature_list`: view the default chosen elemental peaks in the edx dataset.\n",
    "\n",
    "5. `sem.set_feature_list`: set new elemental peaks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjNVT8T9ttZx"
   },
   "source": [
    "## Process the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several (optional) functions to process the dataset:\n",
    "1. `sem.rebin_signal(size=(2,2))`: rebin the edx signal with the size of 2x2. After rebinning the dataset, we can access the binned edx or bse data using `sem.edx_bin` or `sem.bse_bin`.\n",
    "\n",
    "2. `sem.peak_intensity_normalisation()`: normalise the x-ray intensity along energy axis.\n",
    "\n",
    "3. `sem.remove_fist_peak(end=0.1)`: remove the first x-ray peak (most likely noise) by calling the function with the argument `end`.\n",
    "\n",
    "4. `sem.peak_denoising_PCA`: denoise the spectrum using *Principle Component Analysis (PCA)*.\n",
    "\n",
    "    > `n_components_to_reconstruct`: specify how many components to reconstruct the the EDX intensity profile.  \n",
    "    > `plot_results`: True to plot all results.\n",
    "\n",
    "5. `visual.plot_intensity_maps`: Plot the elemental intensity maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kwTAEa5rz7r"
   },
   "outputs": [],
   "source": [
    "# Rebin both edx and bse dataset\n",
    "sem.rebin_signal(size=(2,2))\n",
    "\n",
    "# normalisation to make the spectrum of each pixel summing to 1.\n",
    "sem.peak_intensity_normalisation()\n",
    "\n",
    "# Remove the first peak until the energy of 0.1 keV\n",
    "sem.remove_fist_peak(end=0.1) \n",
    "\n",
    "# Denoise the X-ray profile using PCA.\n",
    "sem.peak_denoising_PCA(n_components_to_reconstruct=10, plot_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NARhLv5ASNry"
   },
   "outputs": [],
   "source": [
    "# View the dataset (bse, edx etc.) again to check differences.\n",
    "gui.view_bcf_dataset(sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing steps yield a HSI datacube with the dimension of 139 x 257 x 9 (due to the 2x2 binning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59GFs_0SBSkW"
   },
   "source": [
    "## Normalisation\n",
    "\n",
    "Before dimensionality reduction, we normalise the elemental maps use `sem.normalisation()`, where we can pass a list containing (optional) sequential normalisation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgCJ-sfVsNbb"
   },
   "outputs": [],
   "source": [
    "# Normalise the dataset using the (optional) sequential three methods.\n",
    "sem.normalisation([norm.neighbour_averaging, \n",
    "                   norm.zscore, \n",
    "                   norm.softmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `gui.view_pixel_distributions` to view the intensity distributions after each sequential normalisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXRo2LvTqxbK"
   },
   "outputs": [],
   "source": [
    "gui.view_pixel_distributions(sem, \n",
    "                             norm_list=[norm.neighbour_averaging,\n",
    "                                        norm.zscore,\n",
    "                                        norm.softmax], \n",
    "                             peak='Fe_Ka', \n",
    "                             cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PaFMEOprt3B"
   },
   "source": [
    "## (Optional) Assign RGB to elemental peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZSQgdJsZTgV"
   },
   "outputs": [],
   "source": [
    "gui.view_rgb(sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check elemental distribution after normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uns525mlsjfm"
   },
   "outputs": [],
   "source": [
    "print('After normalisation:')\n",
    "gui.view_intensity_maps(edx=sem.normalised_elemental_data, element_list=sem.feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2GcAoSlnGuN"
   },
   "source": [
    "# Dimensionality reduction: Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_7bn6yJBjNo"
   },
   "source": [
    "## Initialise experiment / model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUcL2sddrLHC",
    "outputId": "2bc7fd73-d250-40f8-c5b1-755e13058bcb"
   },
   "outputs": [],
   "source": [
    "# The integer in this function can determine different initialised parameters of model (tuning sudo randomness)\n",
    "# This can influence the result of dimensionality reduction and change the latent space.\n",
    "same_seeds(1)\n",
    "\n",
    "# Set up the experiment, e.g. determining the model structure, dataset for training etc.\n",
    "general_results_dir='./' \n",
    "ex = Experiment(descriptor='softmax',\n",
    "                general_results_dir=general_results_dir,\n",
    "                model=AutoEncoder,\n",
    "                model_args={'hidden_layer_sizes':(512,256,128)}, # number of hidden layers and corresponding neurons\n",
    "                chosen_dataset=sem.normalised_elemental_data,\n",
    "                save_model_every_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEgWJf45Bp4F"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgajwhO3rNv1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ex.run_model(num_epochs=100,\n",
    "             patience=50, \n",
    "             batch_size=64,\n",
    "             learning_rate=1e-4, \n",
    "             weight_decay=0.0, \n",
    "             task='train_all', # Change to 'train_eval' to train on the training set (85% dataset) and test on a testing set (15%) for evaluation\n",
    "             noise_added=0.0,\n",
    "             KLD_lambda=0.0,\n",
    "             criterion='MSE',\n",
    "             lr_scheduler_args={'factor':0.5,\n",
    "                                'patience':5, \n",
    "                                'threshold':1e-2, \n",
    "                                'min_lr':1e-6,\n",
    "                                'verbose':True}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd5l795DnL8r"
   },
   "source": [
    "# Pixel segmentation: Gaussian mixture modelling (GMM) clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXi8fj7mBsxt"
   },
   "source": [
    "## (Optional) Load pre-trained Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l8O-UwrjcxP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = './' # model path\n",
    "ex.load_trained_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_qEVkRAV7BL"
   },
   "source": [
    "## Measure Baysian information criterion (BIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gui.view_bic` iteratively calculates the BIC for Gaussian mixture models using the number of Gaussian components `n_components`, e.g. if `n_components=20`, it shows the BIC values for GMM using n_components from 1 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FP2TyaUrL-D0"
   },
   "outputs": [],
   "source": [
    "latent = ex.get_latent()\n",
    "gui.view_bic(latent,\n",
    "             n_components=20,\n",
    "             model_args={'random_state':6, 'init_params':'kmeans'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63qxth1gYc8v"
   },
   "source": [
    "## Run GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyU0I3--rTgM"
   },
   "outputs": [],
   "source": [
    "latent = ex.get_latent()\n",
    "ps = PixelSegmenter(latent, \n",
    "                    sem.normalised_elemental_data, \n",
    "                    sem,\n",
    "                    method_args={'n_components':12, 'random_state':6, 'init_params':'kmeans'} )\n",
    "                    # can change random_state to different integer i.e. 10 or 0 to adjust the clustering result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyVkwD-kwFIF"
   },
   "source": [
    "## Checking latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjrxxOLFrVfu"
   },
   "outputs": [],
   "source": [
    "# Plot latent sapce (2-dimensional) with corresponding Gaussian models\n",
    "gui.view_latent_space(ps, color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKJ_bEDorXpp"
   },
   "outputs": [],
   "source": [
    "# visualise the latent space\n",
    "gui.check_latent_space(ps,ratio_to_be_shown=0.5, show_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47TKUHLorZyV",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the density of latent space\n",
    "gui.plot_latent_density(ps, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uFv-qDOLFye"
   },
   "source": [
    "## Checking each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0fAz4OErbxj"
   },
   "outputs": [],
   "source": [
    "ps.set_feature_list(['Al_Ka', 'C_Ka', 'Ca_Ka', 'Fe_Ka', 'K_Ka', 'O_Ka', 'Si_Ka', 'Ti_Ka', 'Zn_La'])\n",
    "gui.show_cluster_distribution(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7hCyeiKLLii"
   },
   "source": [
    "## Checking cluster map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH9196CXre1j"
   },
   "outputs": [],
   "source": [
    "# Plot phase map using the corresponding GM model\n",
    "gui.view_phase_map(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yizWZ7rrgvx"
   },
   "outputs": [],
   "source": [
    "gui.view_clusters_sum_spectra(ps, normalisation=True, spectra_range=(0,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDqkqAHpLaN0"
   },
   "source": [
    "# Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWeg9UomrmzX"
   },
   "outputs": [],
   "source": [
    "weights, components = ps.get_unmixed_edx_profile(clusters_to_be_calculated='All', \n",
    "                                                 n_components='All',\n",
    "                                                 normalised=False, \n",
    "                                                 method='NMF', \n",
    "                                                 method_args={'init':'nndsvd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "gui.show_unmixed_weights_and_compoments(ps, weights, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSIhNd4oLTHr"
   },
   "source": [
    "# Statistics infro from clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cermaBpurkg7"
   },
   "outputs": [],
   "source": [
    "gui.show_cluster_stats(ps)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Tutorial_local",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
