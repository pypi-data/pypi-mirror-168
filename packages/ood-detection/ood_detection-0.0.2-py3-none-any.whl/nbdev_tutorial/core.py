# AUTOGENERATED! DO NOT EDIT! File to edit: ../00_core.ipynb.

# %% auto 0
__all__ = ['compute_mean_and_cov', 'compute_mahalanobis_distance', 'OODMetric']

# %% ../00_core.ipynb 5
from fastcore.utils import *
import numpy as np

# %% ../00_core.ipynb 6
def compute_mean_and_cov(
    embeds: np.ndarray, # A np.array of size [n_sample, n_dim], where n_sample is the sample size of training set, n_dim is the dimension of the embedding.
    labels: np.ndarray, # A np.array of size [n_sample, ].
    class_ids: np.ndarray # A np.array of the unique class ids in `labels`.
) -> np.ndarray:

    """Computes class-specific means and a shared covariance matrix. 

    Returns:
    means: A list of len n_class, and the i-th element is an np.array of size
        [n_dim, ] corresponding to the mean of the fitted Gaussian distribution
        for the i-th class.
    cov: The shared covariance matrix of the size [n_dim, n_dim].
    """
    n_dim = embeds.shape[1]
    
    cov = np.zeros((n_dim, n_dim)) 
    means = []

    def f(cov, class_id):
        mask = np.expand_dims(labels == class_id, axis=-1) # to compute mean/variance use only those which belong to current class_id
        data = embeds * mask
        mean = np.sum(data, axis=0) / np.sum(mask)
        diff = (data - mean) * mask
        cov += np.matmul(diff.T, diff)
        return cov, mean

    for class_id in class_ids:
        cov, mean = f(cov, class_id)
        means.append(mean)
        
    cov = cov / len(labels)
    return np.stack(means), cov

# %% ../00_core.ipynb 7
def compute_mahalanobis_distance(
    embeds: np.ndarray, # A matrix size [n_test_sample, n_dim], where n_test_sample is the sample size of the test set, and n_dim is the size of the embeddings.
    means: np.ndarray, # A matrix of size [num_classes, n_dim], where the ith row corresponds to the mean of the fitted Gaussian distribution for the i-th class.
    cov: np.ndarray # The shared covariance mmatrix of the size [n_dim, n_dim].
) -> np.ndarray: # A matrix of size [n_test_sample, n_class] where the [i, j] element corresponds to the Mahalanobis distance between i-th sample to the j-th class Gaussian.

    """
    Computes Mahalanobis distance between the input and the fitted Guassians.

    The Mahalanobis distance (Mahalanobis, 1936) is defined as

    $distance(x, mu, sigma) = sqrt((x-\mu)^T \sigma^{-1} (x-\mu))$

    where `x` is a vector, `mu` is the mean vector for a Gaussian, and `sigma` is
    the covariance matrix. We compute the distance for all examples in `embeds`,
    and across all classes in `means`.

    Note that this function technically computes the squared Mahalanobis distance,
    which is consistent with Eq.(2) in <TODO>.
    """
    cov_inv = np.linalg.pinv(cov)
    maha_distances = []

    def maha_dist(x, mean):
        # NOTE: This computes the squared Mahalanobis distance.
        diff = x - mean
        return np.einsum("i,ij,j->", diff, cov_inv, diff)

    for x in embeds:
        arr = []
        for mean in means:
            arr.append(maha_dist(x, mean))
        arr = np.stack(arr)
        maha_distances.append(arr)

    return np.stack(maha_distances)

# %% ../00_core.ipynb 8
class OODMetric:
    """OOD Metric Class that calculates the ood scores for a batch of input embeddings
    
    Initialises the OODMetric class by fitting the class conditional gaussian using training data and the class independent gaussian using training data
    """

    def __init__(self,
                 train_embeds: np.ndarray, # A np.array of size [n_train_sample, n_dim] where n_train_sample is the sample size of training set, n_dim is the dimension of the embedding.
                 train_labels: np.ndarray # A np.array of size [n_train_sample, ]
                ):
        self.means, self.cov = compute_mean_and_cov(train_embeds, train_labels, class_ids=np.unique(train_labels))
        self.means_bg, self.cov_bg = compute_mean_and_cov(train_embeds, np.zeros_like(train_labels), class_ids=np.array([0]))

# %% ../00_core.ipynb 9
@patch
def compute_ood_scores(
    self:OODMetric,
    test_embeds: np.ndarray # A np.array of size [n_test_sample, n_dim], where n_test_sample is the sample size of the test set, and n_dim is the size of the embeddings.
) -> np.ndarray:  # A list of len n_test_sample where the ith element corresponds to the ood score of the ith data point.
    
    distances = compute_mahalanobis_distance(test_embeds, self.means, self.cov)
    distances_bg = compute_mahalanobis_distance(test_embeds, self.means_bg, self.cov_bg)

    rmaha_distances = np.min(distances, axis=-1) - distances_bg[:, 0]
    return rmaha_distances
